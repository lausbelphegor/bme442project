{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (39569, 64, 3)\n",
      "y shape: (19894,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatch between number of samples in X and y.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure that the number of samples is correct for y\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between number of samples in X and y.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Mismatch between number of samples in X and y."
     ]
    }
   ],
   "source": [
    "# Ensure that the number of samples is correct for y\n",
    "if X.shape[0] != y.shape[0]:\n",
    "    raise ValueError(\"Mismatch between number of samples in X and y.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "kernels, chans, samples = 1, X.shape[1], X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validate, and test sets (adjust as needed)\n",
    "train_size = int(0.5 * len(X))\n",
    "validate_size = int(0.25 * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_size:\", train_size)\n",
    "print(\"validate_size:\", validate_size)\n",
    "print(\"test_size:\", len(y) - train_size - validate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:train_size]\n",
    "Y_train = y[:train_size]\n",
    "X_validate = X[train_size:train_size + validate_size]\n",
    "Y_validate = y[train_size:train_size + validate_size]\n",
    "X_test = X[train_size + validate_size:]\n",
    "Y_test = y[train_size + validate_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes of the splits before one-hot encoding\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"X_validate shape:\", X_validate.shape)\n",
    "print(\"Y_validate shape:\", Y_validate.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)\n",
    "print(train_size)\n",
    "print(validate_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_validate = np_utils.to_categorical(Y_validate)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for EEGNet\n",
    "X_train = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_validate = X_validate.reshape(X_validate.shape[0], chans, samples, kernels)\n",
    "X_test = X_test.reshape(X_test.shape[0], chans, samples, kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EEGNet model\n",
    "model = EEGNet(nb_classes=Y_train.shape[1], Chans=chans, Samples=samples,\n",
    "               dropoutRate=0.5, kernLength=32, F1=8, D=2, F2=16,\n",
    "               dropoutType='Dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Set up model checkpointing\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size=16, epochs=300, verbose=2,\n",
    "                        validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "model.load_weights('/tmp/checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "probs = model.predict(X_test)\n",
    "preds = probs.argmax(axis=-1)\n",
    "acc = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyRiemann part (for comparison)\n",
    "n_components = 2\n",
    "clf = make_pipeline(XdawnCovariances(n_components), TangentSpace(metric='riemann'), LogisticRegression())\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], chans, samples)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], chans, samples)\n",
    "clf.fit(X_train_reshaped, Y_train.argmax(axis=-1))\n",
    "preds_rg = clf.predict(X_test_reshaped)\n",
    "acc2 = np.mean(preds_rg == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "names = ['rest', 'left fist', 'right fist', 'both fists', 'both feet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_eegnet = confusion_matrix(Y_test.argmax(axis=-1), preds)\n",
    "disp_eegnet = ConfusionMatrixDisplay(confusion_matrix=cm_eegnet, display_labels=names)\n",
    "disp_eegnet.plot(cmap=plt.cm.Blues)\n",
    "plt.title('EEGNet-8,2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rg = confusion_matrix(Y_test.argmax(axis=-1), preds_rg)\n",
    "disp_rg = ConfusionMatrixDisplay(confusion_matrix=cm_rg, display_labels=names)\n",
    "disp_rg.plot(cmap=plt.cm.Blues)\n",
    "plt.title('xDAWN + RG')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
